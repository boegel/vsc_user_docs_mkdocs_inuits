*[cluster]: A group of compute nodes.
*[compute node]: The computational units on which batch or interactive jobs are processed. A compute node is pretty much comparable to a single personal computer. It contains one or more sockets, each holding a single CPU. Some nodes also contain one or more GPGPUs. The compute node is equipped with memory (RAM) that is accessible by all its CPUs.
*[worker node]: A node attribute is a non-quantitative aspect of a node. Attributes typically describe the node itself or possibly aspects of various node resources such as processors or memory. While it is probably not optimal to aggregate node and resource attributes together in this manner, it is common practice. Common node attributes include processor architecture, operating system, and processor speed. Jobs often specify that resources be allocated from nodes possessing certain node attributes.
*[login node]: On HPC clusters, login nodes serve multiple functions. From a login node you can submit and monitor batch jobs, analyse computational results, run editors, plots, debuggers, compilers, do housekeeping chores as adjust shell settings, copy files and in general manage your account. You connect to these servers when want to start working on the HPC Infrastructure.
*[node attribute]: A node attribute is a non-quantitative aspect of a node. Attributes typically describe the node itself or possibly aspects of various node resources such as processors or memory. While it is probably not optimal to aggregate node and resource attributes together in this manner, it is common practice. Common node attributes include processor architecture, operating system, and processor speed. Jobs often specify that resources be allocated from nodes possessing certain node attributes.
*[node]: A node attribute is a non-quantitative aspect of a node. Attributes typically describe the node itself or possibly aspects of various node resources such as processors or memory. While it is probably not optimal to aggregate node and resource attributes together in this manner, it is common practice. Common node attributes include processor architecture, operating system, and processor speed. Jobs often specify that resources be allocated from nodes possessing certain node attributes.
*[core]: An individual compute unit inside a CPU. A CPU typically contains one or more cores.
*[HPC]: High Performance Computing, high performance computing and multiple-task computing on a supercomputer.
*[CPU]: A central processing unit. A CPU is a consumable resource. A compute node typically contains one or more CPUs
*[FLOPS]: FLOPS is short for ``Floating-point Operations Per second'', i.e., the number of (floating-point) computations that a processor can perform per second.
*[FTP]: File Transfer Protocol, used to copy files between distinct machines (over a network.) FTP is unencrypted, and as such blocked on certain systems. SFTP or SCP are secure alternatives to FTP.
*[GPGPU]: A general purpose graphical processing unit. A GPGPU is a consumable resource. A GPGPU is a GPU that is used for highly parallel general purpose calculations. A compute node may contain zero, one or more GPGPUs.
*[grid]: A group of clusters.
*[L1d]: Level 1 data cache, often called **primary cache**, is a static memory integrated with the CPU core that is used to store data recently accessed by a CPU and also data which may be required by the next operations.
*[L2d]: Level 2 data cache, also called **secondary cache**, is a memory that is used to store recently accessed data and also data, which may be required for the next operations. The goal of having the level 2 cache is to reduce data access time in cases when the same data was already accessed before.
*[L3d]: Level 3 data cache. Extra cache level built into motherboards between the microprocessor and the main memory.
*[LLC]: The Last Level Cache is the last level in the memory hierarchy before main memory. Any memory requests missing here must be serviced by local or remote DRAM, with significant increase in latency when compared with data serviced by the cache memory.
*[InfiniBand]: A high speed switched fabric computer network communications link used in HPC.
*[job constraints]: A set of conditions that must be fulfilled for the job to start.
*[LAN]: Local Area Network
*[Linux]: An operating system, similar to UNIX.
*[distributed memory system]: Computing system consisting of many compute nodes connected by a network, each with their own memory. Accessing memory on a neighbouring node is possible but requires explicit communication.
*[shared memory system]: Computing system in which all the CPUs share one global memory space. However, access times from a CPU to different regions of memory are not necessarily uniform. This is called NUMA: Non-uniform memory access. Memory that is closer to the CPU your process is running on will generally be faster to access than memory that is closer to a different CPU. You can pin processes to a certain CPU to ensure they always use the same memory.
*[memory]: A quantity of physical memory (RAM). Memory is provided by compute nodes. It is required as a constraint or consumed as a consumable resource by jobs. Within Moab, memory is tracked and reported in megabytes (MB).
*[metrics]: A measure of some property, activity or performance of a computer sub-system. These metrics are visualised by graphs in, e.g., Ganglia. 
*[Moab]: Moab is a job scheduler, which allocates resources for jobs that are requesting resources.
*[modules]: HPC uses an open source software package called "Environment Modules" (Modules for short) which allows you to add various path definitions to your shell environment.
*[MPI]: MPI stands for Message-Passing Interface. It supports a parallel programming method designed for distributed memory systems, but can also be used well on shared memory systems.
*[PBS, TORQUE]:  or **OpenPBS** are Open Source resource managers, which are responsible for collecting status and health information from compute nodes and keeping track of jobs running in the system. It is also responsible for spawning the actual executable that is associated with a job, e.g., running the executable on the corresponding compute node. Client commands for submitting and managing jobs can be installed on any host, but in general are installed and used from the Login nodes.
*[processor]: A processing unit. A processor is a consumable resource. A processor can be a CPU or a (GP)GPU.
*[queue]: PBS/TORQUE queues, or "classes" as Moab refers to them, represent groups of computing resources with specific parameters. A queue with a 12-hour runtime or "walltime" would allow jobs requesting 12 hours or less to use this queue.
*[scp]: Secure Copy is a protocol to copy files between distinct machines. SCP or scp is used extensively on HPC clusters to stage in data from outside resources.
*[scratch]: Supercomputers generally have what is called scratch space: storage available for temporary use. Use the scratch filesystem when, for example you are downloading and uncompressed applications, reading and writing input/output data during a batch job, or when you work with large datasets. Scratch is generally a lot faster than the Data or Home filesystem.
*[sftp]: Secure File Transfer Protocol, used to copy files between distinct machines.
*[SSD]: Solid-State Drive. This is a kind of storage device that is faster than a traditional hard disk drive.
*[SSH]: Secure Shell (SSH), sometimes known as Secure Socket Shell, is a Unix-based command interface and protocol for securely getting access to a remote computer. It is widely used by network administrators to control Web and other kinds of servers remotely. SSH is actually a suite of three utilities (slogin, ssh, and scp) that are secure versions of the earlier UNIX utilities, rlogin, rsh, and rcp. SSH commands are encrypted and secure in several ways. Both ends of the client/server connection are authenticated using a digital certificate, and passwords are protected by encryption. Popular implementations include OpenSSH on Linux/Mac and Putty on Windows.
*[ssh-keys]: OpenSSH is a network connectivity tool, which encrypts all traffic including passwords to effectively eliminate eavesdropping, connection hijacking, and other network-level attacks. SSH-keys are part of the OpenSSH bundle. On HPC clusters, ssh-keys allow password-less access between compute nodes while running batch or interactive parallel jobs.
*[supercomputer]: A computer with an extremely high processing capacity or processing power.
*[swap space]: A quantity of virtual memory available for use by batch jobs. Swap is a consumable resource provided by nodes and consumed by jobs.
*[TLB]: Translation Look-aside Buffer, a table in the CPU's memory that contains information about the virtual memory pages the CPU has accessed recently. The table cross-references a program's virtual addresses with the corresponding absolute addresses in physical memory that the program has most recently used. The TLB enables faster computing because it allows the address processing to take place independent of the normal address-translation pipeline.
*[walltime]: Walltime is the length of time specified in the job script for which the job will run on a batch system, you can visualise walltime as the time measured by a wall mounted clock (or your digital wristwatch). This is a computational resource.
*[OpenStack Identity]: OpenStack Identity (Keystone) provides a central directory of users mapped to the OpenStack services they can access. It acts as a common authentication system across the cloud operating system and can integrate with existing backend directory services. It supports multiple forms of authentication including standard username/password credentials and token-based systems. In the VSC cloud, it is integrated with the VSC account system.
*[OpenStack Image]: OpenStack Image (Glance) provides discovery, registration, and delivery services for disk and server images. Stored images can be used as a template. It can also be used to store and catalog an unlimited number of backups. The Image Service can store disk and server images in a variety of back-ends, including Swift.
*[OpenStack Dashboard]: OpenStack Dashboard (Horizon) provides administrators and users with a graphical interface to access, provision, and automate deployment of cloud-based resources. The design accommodates third party products and services, such as billing, monitoring, and additional management tools. The dashboard is also brand-able for service providers and other commercial vendors who want to make use of it. The dashboard is one of several ways users can interact with OpenStack resources. Developers can automate access or build tools to manage resources using the native OpenStack API or the EC2 compatibility API.
*[Terraform]: HashiCorp Terraform is an infrastructure as code tool that lets you define both cloud and on-prem resources in human-readable configuration files that you can version, reuse, and share. You can then use a consistent workflow to provision and manage all of your infrastructure throughout its lifecycle. Terraform can manage low-level components like compute, storage, and networking resources, as well as high-level components like DNS entries and SaaS features.
*[Horizon]: Horizon is the name of the *OpenStack Dashboard*.
*[REST]: REpresentational State Transfer is a software architectural style that defines a set of constraints to be used for creating web services.
*[stack]: In the context of *OpenStack*, a stack is a collection of cloud resources which can be managed using the *Heat* orchestration engine.
*[Heat Orchestration Template]: A Heat Orchestration Template (*HOT*) is a text file which describes the infrastructure for a cloud application. Because *HOT* files are text files in a yaml-based format, they are readable and writable by humans, and can be managed using a version control system. *HOT* is one of the template formats supported by Heat, along with the older CloudFormation-compatible *CFN* format.
*[Heat]: Heat is the OpenStack orchestration service, which can manage multiple composite cloud applications using templates, through both an OpenStack-native REST API and a CloudFormation-compatible Query API.
*[OpenStack Instance]: OpenStack Instances are virtual machines, which are instances of a system image that is created upon request and which is configured when launched. With traditional virtualization technology, the state of the virtual machine is persistent, whereas OpenStack supports both persistent and ephemeral image creation.
*[OpenStack Volume]: OpenStack Volume is a detachable block storage device. Each volume can be attached to only one instance at a time.
*[share]: A share is a remote, mountable file system. Users can mount and access a share on several hosts at a time.
*[yaml]: A human-readable text-based data serialization format.
*[nfs]: Network File System, a protocol for sharing file systems across a network, often used on Unix(-like) operating systems.
*[nic]: Network Interface Controller, a (virtualized) hardware component that connects a computer to a network.
*[OpenStack]: OpenStack (https://www.openstack.org) is a free and open-source software platform for cloud computing, mostly deployed as infrastructure-as-a-service (IaaS), whereby virtual servers and other resources are made available to customers